{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db40ab8d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üì¶ Step 1: Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"‚úÖ Step 1: Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379083c0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üìÇ Step 2: Load data\n",
    "train = pd.read_csv(\"/kaggle/input/retail-forecasting-dataset/train.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/retail-forecasting-dataset/test.csv\")\n",
    "features = pd.read_csv(\"/kaggle/input/retail-forecasting-dataset/features.csv\")\n",
    "stores = pd.read_csv(\"/kaggle/input/retail-forecasting-dataset/stores.csv\")\n",
    "print(\"‚úÖ Step 2: Data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a010adb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üßπ Step 3: Merge datasets\n",
    "train = train.merge(features, on=['Store', 'Date', 'IsHoliday'], how='left')\n",
    "train = train.merge(stores, on='Store', how='left')\n",
    "test = test.merge(features, on=['Store', 'Date', 'IsHoliday'], how='left')\n",
    "test = test.merge(stores, on='Store', how='left')\n",
    "print(\"‚úÖ Step 3: Data merged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29166b9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üóìÔ∏è Step 4: Add date-based features\n",
    "for df in [train, test]:\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['Week'] = df['Date'].dt.isocalendar().week.astype(int)\n",
    "    df['Day'] = df['Date'].dt.dayofweek\n",
    "    df['IsMonthStart'] = df['Date'].dt.is_month_start.astype(int)\n",
    "    df['IsMonthEnd'] = df['Date'].dt.is_month_end.astype(int)\n",
    "    df['WeekOfMonth'] = df['Date'].dt.day // 7 + 1\n",
    "    df['IsWeekend'] = df['Day'].isin([5, 6]).astype(int)\n",
    "print(\"‚úÖ Step 4: Date features added.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c879b333",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üß† Step 5: Create lag and rolling features\n",
    "train = train.sort_values(['Store', 'Dept', 'Date'])\n",
    "train['Lag_1'] = train.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(1)\n",
    "train['Lag_4'] = train.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(4)\n",
    "train['Lag_52'] = train.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(52)\n",
    "\n",
    "train['Rolling_4'] = train.groupby(['Store', 'Dept'])['Weekly_Sales'].transform(lambda x: x.shift(1).rolling(4).mean())\n",
    "train['Sales_Change'] = train['Lag_1'] - train['Lag_4']\n",
    "train = train.dropna()\n",
    "print(\"‚úÖ Step 5: Lag and rolling features created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6fe051",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üßæ Step 6: Feature list\n",
    "features_cols = [\n",
    "    'Store', 'Dept', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment', 'Size',\n",
    "    'IsHoliday', 'Year', 'Month', 'Week', 'Day',\n",
    "    'IsMonthStart', 'IsMonthEnd', 'WeekOfMonth', 'IsWeekend',\n",
    "    'Lag_1', 'Lag_4', 'Lag_52', 'Rolling_4', 'Sales_Change'\n",
    "]\n",
    "\n",
    "X = train[features_cols]\n",
    "y = train['Weekly_Sales']\n",
    "print(\"‚úÖ Step 6: Features and target selected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36996e23",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üß™ Step 7: Train/test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, shuffle=False, test_size=0.2)\n",
    "print(\"‚úÖ Step 7: Data split.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1500a83c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ü§ñ Step 8: Train model\n",
    "model = xgb.XGBRegressor(n_estimators=100, max_depth=8, learning_rate=0.1, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"‚úÖ Step 8: Model trained.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5298a812",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üìâ Step 9: Evaluate model\n",
    "val_preds = model.predict(X_val)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "print(f\"‚úÖ Step 9: Model evaluated. Validation RMSE: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b8c6e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üìä Step 10: Plot actual vs predicted\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(y_val.values[:100], label=\"Actual\")\n",
    "plt.plot(val_preds[:100], label=\"Predicted\")\n",
    "plt.title(\"Actual vs Predicted Sales (Sample)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"‚úÖ Step 10: Plot displayed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c602e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üîç Step 11: SHAP analysis\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X_val[:200])  # subset for speed\n",
    "shap.plots.beeswarm(shap_values)\n",
    "print(\"‚úÖ Step 11: SHAP analysis done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2092f4e1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üöÄ Step 12: Predict on test set (fill missing lag features with median)\n",
    "test['Lag_1'] = train['Lag_1'].median()\n",
    "test['Lag_4'] = train['Lag_4'].median()\n",
    "test['Lag_52'] = train['Lag_52'].median()\n",
    "test['Rolling_4'] = train['Rolling_4'].median()\n",
    "test['Sales_Change'] = train['Sales_Change'].median()\n",
    "\n",
    "X_test = test[features_cols]\n",
    "test['Weekly_Sales'] = model.predict(X_test)\n",
    "print(\"‚úÖ Step 12: Predictions made on test set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509c193a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# üíæ Step 13: Save results\n",
    "submission = test[['Store', 'Dept', 'Date', 'Weekly_Sales']]\n",
    "submission.to_csv(\"enhanced_sales_predictions.csv\", index=False)\n",
    "print(\"‚úÖ Step 13: Submission file saved as 'enhanced_sales_predictions.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57fa364",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0a3e5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc5f36e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
